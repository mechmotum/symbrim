name: Tests

on:
  pull_request:
  push:
    branches:
      - main

jobs:

  #---------------------------------- download-data -----------------------------------#

  download-data:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - name: Download parametrization data
        run: |
          git clone --depth 1 https://github.com/moorepants/BicycleParameters.git
          mv BicycleParameters/data data
          rm -rf BicycleParameters
      - name: Upload data directory
        uses: actions/upload-artifact@v6
        with:
          name: data
          path: data

  #----------------------------------- code-quality -----------------------------------#

  code-quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - name: Install uv
        uses: astral-sh/setup-uv@v7
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.13"
      - name: Install dependencies
        run: uv sync --all-extras
      - name: Lint check with ruff
        run: uv run ruff check .

  #-------------------------------------- tests ---------------------------------------#

  tests:
    needs: code-quality

    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12", "3.13"]
    steps:
      - uses: actions/checkout@v6
      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          python-version: ${{ matrix.python-version }}
      - name: Download data directory
        uses: actions/download-artifact@v6
        with:
          name: data
          path: data
      - name: Install dependencies
        run: uv sync --all-extras
      - name: Run tests
        run: uv run pytest -n auto

  #------------------------------------ doc-tests -------------------------------------#

  slow-tests:
    needs: tests

    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - name: Install uv
        uses: astral-sh/setup-uv@v7
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: 3.13
      - name: Download data directory
        uses: actions/download-artifact@v6
        with:
          name: data
          path: data
      - name: Install dependencies
        run: uv sync --all-extras
      - name: Run slow tests
        run: uv run pytest -n auto -m "slow"

  #------------------------------------ doc-tests -------------------------------------#

  test_docs_job:
    needs: code-quality

    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12", "3.13"]
    steps:
      - name: Checkout
        uses: actions/checkout@v6
      - name: Install pandoc
        run: |
          sudo apt-get update
          sudo apt-get install pandoc
      - name: Create the tutorials' environment
        uses: mamba-org/setup-micromamba@v2
        with:
          environment-file: docs/tutorials/tutorials_environment.yml
          init-shell: >-
            bash
            powershell
          cache-environment: true
          post-cleanup: 'all'
      - name: Deactivate the tutorials environment
        run: |
          source /usr/share/miniconda/etc/profile.d/conda.sh
          conda deactivate
      - name: Install uv
        uses: astral-sh/setup-uv@v7
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: uv sync --all-extras
      - name: make the sphinx docs
        run: |
          uv run make -C docs clean
          uv run make -C docs html

  #--------------------------------- test benchmarks ----------------------------------#

  test_benchmarks:
    needs: tests

    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - name: Install uv
        uses: astral-sh/setup-uv@v7
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: 3.13
      - name: Install dependencies
        run: uv sync --all-extras
      - name: Run benchmarks
        run: uv run pytest ./benchmarks/ --benchmark-json=benchmark-results.json --benchmark-autosave

      # Store benchmark results as artifact
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            benchmark-results.json
            .benchmarks/

      # Create PR comment with benchmark results
      - name: Comment benchmark results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Read benchmark results
            let benchmarkData;
            try {
              benchmarkData = JSON.parse(fs.readFileSync('benchmark-results.json', 'utf8'));
            } catch (error) {
              console.log('Could not read benchmark results:', error);
              return;
            }
            
            // Format benchmark results as markdown table
            let comment = '## ðŸ“Š Benchmark Results\n\n';
            
            // Group benchmarks
            const groups = {};
            for (const benchmark of benchmarkData.benchmarks) {
              const group = benchmark.group || 'default';
              if (!groups[group]) {
                groups[group] = [];
              }
              groups[group].push(benchmark);
            }
            
            // Create tables for each group
            for (const [groupName, benchmarks] of Object.entries(groups)) {
              comment += `### ${groupName}\n\n`;
              comment += '| Name | Mean (ms) | #Ops | #Ops (CSE) |\n';
              comment += '|------|-----------|------|------------|\n';
              
              for (const bench of benchmarks) {
                const name = bench.name;
                const mean = (bench.stats.mean * 1000).toFixed(2);
                const ops = bench.extra_info?.operation_eoms || 'N/A';
                const opsCse = bench.extra_info?.operation_eoms_csed || 'N/A';
                comment += `| ${name} | ${mean} | ${ops} | ${opsCse} |\n`;
              }
              comment += '\n';
            }
            
            comment += 'ðŸ’¡ Lower operation counts (especially after CSE) indicate more efficient symbolic computations.\n';
            
            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('ðŸ“Š Benchmark Results')
            );
            
            // Create or update comment
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

    #--------------------------------- code-coverage ----------------------------------#

  code-coverage:
    needs: tests

    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - name: Install uv
        uses: astral-sh/setup-uv@v7
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: 3.13
      - name: Download data directory
        uses: actions/download-artifact@v4
        with:
          name: data
          path: data
      - name: Install dependencies
        run: uv sync --all-extras
      - name: Run tests with code coverage
        run: uv run pytest --cov -n auto
